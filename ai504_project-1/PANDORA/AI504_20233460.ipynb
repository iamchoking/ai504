{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":25531,"status":"ok","timestamp":1729573914347,"user":{"displayName":"Hyungho Chris Choi","userId":"14281865657109613854"},"user_tz":-540},"id":"Pn_GKSqBkdvX"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1729573914348,"user":{"displayName":"Hyungho Chris Choi","userId":"14281865657109613854"},"user_tz":-540},"id":"LMG7M8kWkrLC"},"outputs":[],"source":["class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_channels != out_channels:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","\n","        self.relu = nn.ReLU(inplace=True)\n","        self.dropout = nn.Dropout2d(0.1)\n","\n","    def forward(self, x):\n","        out = self.relu(self.bn1(self.conv1(x)))\n","        out = self.dropout(out)\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = self.relu(out)\n","        return out\n","\n","class FashionMNIST(nn.Module):\n","    def __init__(self):\n","        super(FashionMNIST, self).__init__()\n","\n","        # Initial convolution\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","        # Residual blocks\n","        self.layer1 = self.make_layer(64, 64, 2)\n","        self.layer2 = self.make_layer(64, 128, 2, stride=2)\n","        self.layer3 = self.make_layer(128, 256, 2, stride=2)\n","\n","        # Global average pooling and classifier\n","        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Sequential(\n","            nn.Linear(256, 128),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(0.5),\n","            nn.Linear(128, 10)\n","        )\n","\n","    def make_layer(self, in_channels, out_channels, num_blocks, stride=1):\n","        layers = []\n","        layers.append(ResidualBlock(in_channels, out_channels, stride))\n","        for _ in range(1, num_blocks):\n","            layers.append(ResidualBlock(out_channels, out_channels))\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.avg_pool(out)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc(out)\n","        return out"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1729573914348,"user":{"displayName":"Hyungho Chris Choi","userId":"14281865657109613854"},"user_tz":-540},"id":"Xu8_Yzb9k6bX"},"outputs":[],"source":["def get_data_loaders(batch_size=64):\n","    transform = transforms.Compose([transforms.ToTensor()])\n","    train_set = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n","    test_set = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n","\n","    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n","\n","    return train_loader, test_loader\n","\n","def save_logits(model, test_loader, device, studentID):\n","    model.eval()\n","    logits_list = []\n","\n","    with torch.no_grad():\n","        for images, _ in test_loader:\n","            images = images.to(device)\n","            outputs = model(images)\n","            logits_list.append(outputs.cpu().numpy())\n","\n","    logits = np.vstack(logits_list)\n","    np.save(f'{studentID}.npy', logits)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1729573914348,"user":{"displayName":"Hyungho Chris Choi","userId":"14281865657109613854"},"user_tz":-540},"id":"i4q3lwdPl2vr"},"outputs":[],"source":["# Training function\n","def train_model(model, train_loader, test_loader, epochs=30, device=\"cuda\"):\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n","    scheduler = optim.lr_scheduler.OneCycleLR(\n","        optimizer, max_lr=0.01, epochs=epochs, steps_per_epoch=len(train_loader))\n","\n","    best_acc = 0.0\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        running_loss = 0.0\n","        correct = 0\n","        total = 0\n","\n","        for batch_idx, (inputs, targets) in enumerate(train_loader):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","\n","            running_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","            if batch_idx % 100 == 99:\n","                print(f'Epoch: {epoch+1}, Batch: {batch_idx+1}, Loss: {running_loss/100:.3f}, '\n","                      f'Acc: {100.*correct/total:.2f}%')\n","                running_loss = 0.0\n","\n","        model.eval()\n","        test_correct = 0\n","        test_total = 0\n","\n","        with torch.no_grad():\n","            for inputs, targets in test_loader:\n","                inputs, targets = inputs.to(device), targets.to(device)\n","                outputs = model(inputs)\n","                _, predicted = outputs.max(1)\n","                test_total += targets.size(0)\n","                test_correct += predicted.eq(targets).sum().item()\n","\n","        test_acc = 100. * test_correct / test_total\n","        print(f'Epoch: {epoch+1}, Test Accuracy: {test_acc:.2f}%')\n","\n","        if test_acc \u003e best_acc:\n","            best_acc = test_acc\n","            torch.save(model.state_dict(), 'best_fashion_mnist.pth')\n","\n","    return best_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"bMr8l1JNl4gQ"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 26421880/26421880 [00:12\u003c00:00, 2148083.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 29515/29515 [00:00\u003c00:00, 209601.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4422102/4422102 [00:06\u003c00:00, 722952.65it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5148/5148 [00:00\u003c00:00, 16101623.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Epoch: 1, Batch: 100, Loss: 1.161, Acc: 58.48%\n","Epoch: 1, Batch: 200, Loss: 0.715, Acc: 66.12%\n","Epoch: 1, Batch: 300, Loss: 0.609, Acc: 70.24%\n","Epoch: 1, Batch: 400, Loss: 0.530, Acc: 73.14%\n","Epoch: 1, Batch: 500, Loss: 0.500, Acc: 75.00%\n","Epoch: 1, Batch: 600, Loss: 0.475, Acc: 76.29%\n","Epoch: 1, Batch: 700, Loss: 0.457, Acc: 77.34%\n","Epoch: 1, Batch: 800, Loss: 0.449, Acc: 78.19%\n","Epoch: 1, Batch: 900, Loss: 0.436, Acc: 78.91%\n","Epoch: 1, Test Accuracy: 85.47%\n","Epoch: 2, Batch: 100, Loss: 0.407, Acc: 85.44%\n","Epoch: 2, Batch: 200, Loss: 0.366, Acc: 86.34%\n","Epoch: 2, Batch: 300, Loss: 0.391, Acc: 86.26%\n","Epoch: 2, Batch: 400, Loss: 0.389, Acc: 86.22%\n","Epoch: 2, Batch: 500, Loss: 0.390, Acc: 86.25%\n","Epoch: 2, Batch: 600, Loss: 0.354, Acc: 86.44%\n","Epoch: 2, Batch: 700, Loss: 0.346, Acc: 86.67%\n"]}],"source":["def main():\n","    studentID = \"20233460\"\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    train_loader, test_loader = get_data_loaders()\n","\n","    model = FashionMNIST().to(device)\n","\n","    best_acc = train_model(model, train_loader, test_loader, device=device)\n","\n","    save_logits(model, test_loader, device, studentID)\n","\n","    print(f'Best Test Accuracy: {best_acc:.2f}%')\n","\n","if __name__ == '__main__':\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hKgpw2I7m5Ls"},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}